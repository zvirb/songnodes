# ===============================================================================
# Alertmanager Configuration - SongNodes Monitoring
# ===============================================================================
# This configuration routes alerts to Slack channels based on severity,
# component, and alert type. Designed for scraper monitoring with intelligent
# grouping and routing.
# ===============================================================================

global:
  resolve_timeout: 5m
  # Slack API URL should be set via environment variable for security
  # Set SLACK_WEBHOOK_URL in docker-compose or kubernetes secrets

# ===============================================================================
# ROUTING CONFIGURATION
# ===============================================================================
# Routes determine how alerts are grouped and which receiver handles them
route:
  receiver: 'slack-default'
  group_by: ['alertname', 'severity', 'scraper_name', 'component']
  group_wait: 30s        # Wait 30s before sending first notification (batch initial alerts)
  group_interval: 5m     # Wait 5m before sending batched updates
  repeat_interval: 4h    # Send reminder every 4 hours if alert still firing

  routes:
    # -------------------------------------------------------------------------
    # CRITICAL ALERTS - Immediate notification with paging
    # -------------------------------------------------------------------------
    - match:
        severity: critical
      receiver: 'slack-critical'
      group_wait: 10s           # Faster notification for critical issues
      group_interval: 2m
      repeat_interval: 15m      # More frequent reminders
      continue: true            # Also send to default channel

    # -------------------------------------------------------------------------
    # SCRAPER-SPECIFIC ROUTING
    # -------------------------------------------------------------------------
    # Scraper health and performance alerts
    - match:
        component: scraper
      receiver: 'slack-scraper-alerts'
      group_by: ['alertname', 'scraper_name', 'severity']
      group_wait: 1m
      repeat_interval: 2h

    # Scraper data quality alerts
    - match_re:
        alertname: '^Scraper.*(Quality|Schema|Validation|Enrichment).*'
      receiver: 'slack-data-quality'
      group_by: ['alertname', 'scraper_name', 'item_type']
      group_wait: 2m
      repeat_interval: 3h

    # Scraper extraction failures
    - match:
        component: extraction
      receiver: 'slack-scraper-extraction'
      group_by: ['alertname', 'scraper_name', 'failure_reason']
      group_wait: 1m
      repeat_interval: 2h

    # -------------------------------------------------------------------------
    # INFRASTRUCTURE ROUTING
    # -------------------------------------------------------------------------
    # Database alerts
    - match:
        component: database
      receiver: 'slack-database'
      group_by: ['alertname', 'severity']
      group_wait: 30s
      repeat_interval: 30m

    # Infrastructure/container alerts
    - match:
        component: infrastructure
      receiver: 'slack-infrastructure'
      group_by: ['alertname', 'severity']
      group_wait: 1m
      repeat_interval: 1h

    # Performance alerts
    - match:
        component: performance
      receiver: 'slack-performance'
      group_by: ['alertname', 'service']
      group_interval: 5m
      repeat_interval: 2h

    # -------------------------------------------------------------------------
    # SERVICE-SPECIFIC ROUTING
    # -------------------------------------------------------------------------
    # Service down - immediate notification
    - match:
        alertname: ServiceDown
      receiver: 'slack-service-down'
      group_wait: 10s
      repeat_interval: 10m
      continue: true

    # Graph API alerts
    - match:
        component: graph-api
      receiver: 'slack-graph-api'
      group_wait: 1m
      repeat_interval: 1h

    # WebSocket alerts
    - match:
        component: websocket
      receiver: 'slack-websocket'
      group_wait: 30s
      repeat_interval: 1h

    # -------------------------------------------------------------------------
    # WARNING ALERTS
    # -------------------------------------------------------------------------
    - match:
        severity: warning
      receiver: 'slack-warnings'
      group_wait: 2m
      group_interval: 10m
      repeat_interval: 6h

    # -------------------------------------------------------------------------
    # INFO ALERTS
    # -------------------------------------------------------------------------
    - match:
        severity: info
      receiver: 'slack-info'
      group_wait: 5m
      group_interval: 15m
      repeat_interval: 12h

# ===============================================================================
# RECEIVERS CONFIGURATION
# ===============================================================================
# Define Slack notification channels for different alert types
receivers:
  # ---------------------------------------------------------------------------
  # DEFAULT RECEIVER - All alerts
  # ---------------------------------------------------------------------------
  - name: 'slack-default'
    slack_configs:
      - channel: '#songnodes-alerts'
        username: 'Alertmanager'
        icon_emoji: ':bell:'
        title: '{{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Severity:* {{ .Labels.severity }}
          {{ if .Labels.scraper_name }}*Scraper:* {{ .Labels.scraper_name }}{{ end }}
          {{ if .Labels.component }}*Component:* {{ .Labels.component }}{{ end }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ if .Annotations.dashboard_url }}*Dashboard:* {{ .Annotations.dashboard_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}'

  # ---------------------------------------------------------------------------
  # CRITICAL ALERTS - P1/P0 incidents
  # ---------------------------------------------------------------------------
  - name: 'slack-critical'
    slack_configs:
      - channel: '#songnodes-critical'
        username: 'Critical Alert'
        icon_emoji: ':rotating_light:'
        color: 'danger'
        title: ':rotating_light: CRITICAL: {{ .GroupLabels.alertname }}'
        title_link: '{{ if .CommonAnnotations.dashboard_url }}{{ .CommonAnnotations.dashboard_url }}{{ end }}'
        text: |
          <!channel> *CRITICAL ALERT FIRED*

          {{ range .Alerts }}
          ---
          *Alert:* {{ .Annotations.summary }}
          *Priority:* {{ .Labels.priority | default "P1" }}
          *Team:* {{ .Labels.team | default "platform" }}
          {{ if .Labels.scraper_name }}*Scraper:* `{{ .Labels.scraper_name }}`{{ end }}
          {{ if .Labels.component }}*Component:* {{ .Labels.component }}{{ end }}

          *Description:*
          {{ .Annotations.description }}

          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ if .Annotations.dashboard_url }}*Dashboard:* {{ .Annotations.dashboard_url }}{{ end }}
          {{ if .Annotations.action }}*Action Required:* {{ .Annotations.action }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_CRITICAL:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # SCRAPER ALERTS - General scraper health and performance
  # ---------------------------------------------------------------------------
  - name: 'slack-scraper-alerts'
    slack_configs:
      - channel: '#songnodes-scraper-alerts'
        username: 'Scraper Monitor'
        icon_emoji: ':spider_web:'
        title: 'Scraper Alert: {{ .GroupLabels.alertname }}'
        text: |
          *Scraper:* {{ .GroupLabels.scraper_name | default "Unknown" }}
          *Severity:* {{ .GroupLabels.severity }}

          {{ range .Alerts }}
          ---
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          {{ if .Labels.source }}*Source:* {{ .Labels.source }}{{ end }}
          {{ if .Labels.container_id }}*Container:* {{ .Labels.container_id }}{{ end }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_SCRAPERS:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # DATA QUALITY ALERTS - Schema, validation, enrichment
  # ---------------------------------------------------------------------------
  - name: 'slack-data-quality'
    slack_configs:
      - channel: '#songnodes-data-quality'
        username: 'Data Quality Monitor'
        icon_emoji: ':bar_chart:'
        title: 'Data Quality Alert: {{ .GroupLabels.alertname }}'
        text: |
          *Scraper:* {{ .GroupLabels.scraper_name | default "Unknown" }}
          {{ if .GroupLabels.item_type }}*Item Type:* {{ .GroupLabels.item_type }}{{ end }}

          {{ range .Alerts }}
          ---
          *Summary:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          {{ if .Labels.error_type }}*Error Type:* {{ .Labels.error_type }}{{ end }}
          {{ if .Labels.validation_type }}*Validation Type:* {{ .Labels.validation_type }}{{ end }}
          {{ if .Labels.enrichment_source }}*Enrichment Source:* {{ .Labels.enrichment_source }}{{ end }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_DATA_QUALITY:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # EXTRACTION ALERTS - Scraping failures and extraction issues
  # ---------------------------------------------------------------------------
  - name: 'slack-scraper-extraction'
    slack_configs:
      - channel: '#songnodes-extraction-alerts'
        username: 'Extraction Monitor'
        icon_emoji: ':mag:'
        title: 'Extraction Alert: {{ .GroupLabels.alertname }}'
        text: |
          *Scraper:* {{ .GroupLabels.scraper_name | default "Unknown" }}
          {{ if .GroupLabels.failure_reason }}*Failure Reason:* {{ .GroupLabels.failure_reason }}{{ end }}

          {{ range .Alerts }}
          ---
          *Summary:* {{ .Annotations.summary }}
          {{ if .Labels.url_pattern }}*URL Pattern:* {{ .Labels.url_pattern }}{{ end }}
          {{ if .Labels.extraction_type }}*Extraction Type:* {{ .Labels.extraction_type }}{{ end }}

          *Description:*
          {{ .Annotations.description }}

          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_EXTRACTION:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # DATABASE ALERTS
  # ---------------------------------------------------------------------------
  - name: 'slack-database'
    slack_configs:
      - channel: '#songnodes-database-alerts'
        username: 'Database Monitor'
        icon_emoji: ':floppy_disk:'
        title: 'Database Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Severity:* {{ .Labels.severity }}
          *Description:* {{ .Annotations.description }}
          {{ if .Labels.pool_type }}*Pool Type:* {{ .Labels.pool_type }}{{ end }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_DATABASE:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # INFRASTRUCTURE ALERTS
  # ---------------------------------------------------------------------------
  - name: 'slack-infrastructure'
    slack_configs:
      - channel: '#songnodes-infrastructure'
        username: 'Infrastructure Monitor'
        icon_emoji: ':gear:'
        title: 'Infrastructure Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Severity:* {{ .Labels.severity }}
          *Description:* {{ .Annotations.description }}
          {{ if .Labels.instance }}*Instance:* {{ .Labels.instance }}{{ end }}
          {{ if .Annotations.impact }}*Impact:* {{ .Annotations.impact }}{{ end }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_INFRA:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # PERFORMANCE ALERTS
  # ---------------------------------------------------------------------------
  - name: 'slack-performance'
    slack_configs:
      - channel: '#songnodes-performance'
        username: 'Performance Monitor'
        icon_emoji: ':chart_with_upwards_trend:'
        title: 'Performance Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          {{ if .Labels.service }}*Service:* {{ .Labels.service }}{{ end }}
          {{ if .Annotations.threshold }}*Threshold:* {{ .Annotations.threshold }}{{ end }}
          {{ if .Annotations.current_value }}*Current Value:* {{ .Annotations.current_value }}{{ end }}
          *Description:* {{ .Annotations.description }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_PERFORMANCE:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # SERVICE DOWN ALERTS
  # ---------------------------------------------------------------------------
  - name: 'slack-service-down'
    slack_configs:
      - channel: '#songnodes-service-down'
        username: 'Service Monitor'
        icon_emoji: ':x:'
        color: 'danger'
        title: ':x: SERVICE DOWN: {{ .GroupLabels.alertname }}'
        text: |
          <!here> *SERVICE DOWN DETECTED*

          {{ range .Alerts }}
          *Service:* {{ .Labels.job }}
          *Instance:* {{ .Labels.instance }}
          *Duration:* {{ .Annotations.for | default "Unknown" }}
          *Description:* {{ .Annotations.description }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_SERVICE_DOWN:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # GRAPH API ALERTS
  # ---------------------------------------------------------------------------
  - name: 'slack-graph-api'
    slack_configs:
      - channel: '#songnodes-graph-api'
        username: 'Graph API Monitor'
        icon_emoji: ':globe_with_meridians:'
        title: 'Graph API Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          {{ if .Annotations.impact }}*Impact:* {{ .Annotations.impact }}{{ end }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_GRAPH_API:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # WEBSOCKET ALERTS
  # ---------------------------------------------------------------------------
  - name: 'slack-websocket'
    slack_configs:
      - channel: '#songnodes-websocket'
        username: 'WebSocket Monitor'
        icon_emoji: ':electric_plug:'
        title: 'WebSocket Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          {{ if .Annotations.impact }}*Impact:* {{ .Annotations.impact }}{{ end }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_WEBSOCKET:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # WARNING ALERTS
  # ---------------------------------------------------------------------------
  - name: 'slack-warnings'
    slack_configs:
      - channel: '#songnodes-warnings'
        username: 'Warning Monitor'
        icon_emoji: ':warning:'
        color: 'warning'
        title: ':warning: Warning: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          {{ if .Labels.component }}*Component:* {{ .Labels.component }}{{ end }}
          *Description:* {{ .Annotations.description }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_WARNINGS:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # INFO ALERTS
  # ---------------------------------------------------------------------------
  - name: 'slack-info'
    slack_configs:
      - channel: '#songnodes-info'
        username: 'Info Monitor'
        icon_emoji: ':information_source:'
        color: 'good'
        title: ':information_source: Info: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          {{ if .Labels.component }}*Component:* {{ .Labels.component }}{{ end }}
          *Description:* {{ .Annotations.description }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_INFO:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

# ===============================================================================
# INHIBITION RULES
# ===============================================================================
# Prevent alert noise by suppressing redundant notifications
inhibit_rules:
  # If a service is down, suppress other alerts for that service
  - source_match:
      alertname: 'ServiceDown'
    target_match_re:
      alertname: '.*'
    equal: ['job', 'instance']

  # If a container is unhealthy, suppress performance alerts for that scraper
  - source_match:
      alertname: 'ScraperContainerUnhealthy'
    target_match:
      component: 'performance'
    equal: ['scraper_name']

  # If database is down, suppress connection pool alerts
  - source_match:
      alertname: 'PostgreSQLDown'
    target_match_re:
      alertname: '.*Database.*'
    equal: ['instance']

  # If all extractions are failing, suppress individual extraction failures
  - source_match:
      alertname: 'ScraperAllExtractionsFailing'
    target_match:
      alertname: 'ScraperHighExtractionFailureRate'
    equal: ['scraper_name']

  # Critical alerts suppress warnings for same issue
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'scraper_name']

  # If enrichment service is down, suppress enrichment failure alerts
  - source_match:
      alertname: 'ServiceDown'
      job: 'metadata-enrichment'
    target_match_re:
      alertname: 'Scraper.*Enrichment.*'