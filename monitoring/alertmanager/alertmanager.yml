# Alertmanager Configuration - Development Environment
global:
  resolve_timeout: 5m
  # SMTP disabled for development - no email server available
  # smtp_smarthost: 'localhost:25'
  # smtp_from: 'alertmanager@songnodes.local'
  # smtp_require_tls: false

# Route tree for alert routing
route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'default'

  routes:
    # Critical alerts - immediate notification
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 5s
      repeat_interval: 15m

    # Database alerts
    - match:
        component: database
      receiver: 'database-team'
      group_wait: 30s
      repeat_interval: 30m

    # Performance alerts
    - match_re:
        alertname: '^(HighResponseTime|HighCPU|HighMemory).*'
      receiver: 'performance-team'
      group_interval: 5m
      repeat_interval: 2h

    # Service down alerts
    - match:
        alertname: ServiceDown
      receiver: 'oncall'
      group_wait: 10s
      repeat_interval: 10m

# Receivers configuration - Development mode (alerts logged but not sent)
receivers:
  - name: 'default'
    # Development: No webhook receiver configured
    # Alerts are logged in Alertmanager UI only
    # For production: Add webhook_configs, email_configs, or slack_configs

  - name: 'critical-alerts'
    # Development: No notifications configured
    # For production: Add email/Slack/PagerDuty integration

  - name: 'database-team'
    # Development: No notifications configured
    # For production: Add team-specific notification channels

  - name: 'performance-team'
    # Development: No notifications configured
    # For production: Add performance team channels

  - name: 'oncall'
    # Development: No notifications configured
    # For production: Add on-call rotation integration

# Inhibition rules to suppress certain alerts
inhibit_rules:
  # If a service is down, suppress other alerts for that service
  - source_match:
      alertname: 'ServiceDown'
    target_match_re:
      alertname: '.*'
    equal: ['service']

  # If database is down, suppress dependent service alerts
  - source_match:
      alertname: 'PostgreSQLDown'
    target_match:
      severity: 'warning'
    equal: ['cluster']