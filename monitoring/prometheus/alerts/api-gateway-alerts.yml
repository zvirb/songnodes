groups:
  - name: api_gateway_critical
    interval: 30s
    rules:
      # Circuit Breaker Alerts
      - alert: CircuitBreakerOpen
        expr: api_gateway_circuit_breaker_state > 0
        for: 1m
        labels:
          severity: critical
          component: api_gateway
          pattern: circuit_breaker
        annotations:
          summary: "Circuit breaker OPEN for {{ $labels.provider }}"
          description: "The circuit breaker for {{ $labels.provider }} has transitioned to OPEN or HALF_OPEN state, indicating repeated failures. Current state: {{ $value }}. Check provider health and error logs."
          runbook_url: "https://docs.songnodes.com/runbooks/circuit-breaker-open"

      - alert: CircuitBreakerApproachingThreshold
        expr: |
          (api_gateway_circuit_breaker_failures / api_gateway_circuit_breaker_threshold) > 0.8
        for: 2m
        labels:
          severity: warning
          component: api_gateway
          pattern: circuit_breaker
        annotations:
          summary: "Circuit breaker for {{ $labels.provider }} approaching failure threshold"
          description: "{{ $labels.provider }} has {{ $value | humanizePercentage }} of failures relative to threshold. Circuit breaker may open soon."

      # Rate Limiter Alerts
      - alert: RateLimiterTokenExhaustion
        expr: |
          (api_gateway_rate_limiter_tokens_available / api_gateway_rate_limiter_capacity) < 0.1
        for: 3m
        labels:
          severity: warning
          component: api_gateway
          pattern: rate_limiter
        annotations:
          summary: "Rate limiter for {{ $labels.provider }} running low on tokens"
          description: "{{ $labels.provider }} rate limiter has less than 10% tokens available ({{ $value | humanizePercentage }}). Requests may be throttled."

      - alert: RateLimiterFullyExhausted
        expr: api_gateway_rate_limiter_tokens_available == 0
        for: 1m
        labels:
          severity: critical
          component: api_gateway
          pattern: rate_limiter
        annotations:
          summary: "Rate limiter for {{ $labels.provider }} completely exhausted"
          description: "{{ $labels.provider }} has NO available tokens. All requests are being blocked or delayed. Check if rate limits need adjustment."

      # Rate Limit Prediction Alerts (NEW)
      - alert: RateLimitExhaustionPredictedSoon
        expr: |
          api_gateway_rate_limit_exhaustion_predicted_seconds > 0
          and api_gateway_rate_limit_exhaustion_predicted_seconds < 300
        for: 1m
        labels:
          severity: warning
          component: api_gateway
          pattern: rate_limiter_prediction
        annotations:
          summary: "Rate limit exhaustion predicted within 5 minutes for {{ $labels.provider }}"
          description: "{{ $labels.provider }} rate limit will be exhausted in approximately {{ $value }} seconds based on current consumption patterns. Consider throttling requests or increasing rate limits."
          runbook_url: "https://docs.songnodes.com/runbooks/rate-limit-prediction"

      - alert: RateLimitExhaustionImminent
        expr: |
          api_gateway_rate_limit_exhaustion_predicted_seconds > 0
          and api_gateway_rate_limit_exhaustion_predicted_seconds < 60
        for: 30s
        labels:
          severity: critical
          component: api_gateway
          pattern: rate_limiter_prediction
        annotations:
          summary: "CRITICAL: Rate limit exhaustion imminent for {{ $labels.provider }}"
          description: "{{ $labels.provider }} rate limit will be exhausted in {{ $value }} seconds! Immediate action required: throttle requests, pause scraping, or increase rate limits."

      - alert: TokenBucketFillRatioCritical
        expr: api_gateway_rate_limit_token_bucket_fill_ratio < 0.2
        for: 2m
        labels:
          severity: warning
          component: api_gateway
          pattern: rate_limiter_prediction
        annotations:
          summary: "Token bucket for {{ $labels.provider }} below 20% capacity"
          description: "{{ $labels.provider }} token bucket is at {{ $value | humanizePercentage }} capacity. Rate limit may be under sustained high load."

      # Cache Performance Alerts
      - alert: CacheHitRateLow
        expr: |
          (
            sum(rate(api_gateway_cache_hits_total[5m])) by (provider) /
            (sum(rate(api_gateway_cache_hits_total[5m])) by (provider) + sum(rate(api_gateway_cache_misses_total[5m])) by (provider))
          ) < 0.3
        for: 10m
        labels:
          severity: warning
          component: api_gateway
          pattern: cache
        annotations:
          summary: "Low cache hit rate for {{ $labels.provider }}"
          description: "{{ $labels.provider }} cache hit rate is {{ $value | humanizePercentage }}. Expected >60%. Check cache TTL settings and Redis health."

      - alert: CacheHitRateCriticallyLow
        expr: |
          (
            sum(rate(api_gateway_cache_hits_total[5m])) by (provider) /
            (sum(rate(api_gateway_cache_hits_total[5m])) by (provider) + sum(rate(api_gateway_cache_misses_total[5m])) by (provider))
          ) < 0.1
        for: 5m
        labels:
          severity: critical
          component: api_gateway
          pattern: cache
        annotations:
          summary: "CRITICAL: Cache hit rate for {{ $labels.provider }} below 10%"
          description: "{{ $labels.provider }} cache is essentially not working ({{ $value | humanizePercentage }} hit rate). Check Redis connectivity and cache configuration."

      # Dead Letter Queue Alerts
      - alert: DLQMessagesAccumulating
        expr: sum(api_gateway_dlq_messages_total) > 10
        for: 5m
        labels:
          severity: warning
          component: api_gateway
          pattern: dlq
        annotations:
          summary: "Dead Letter Queue accumulating messages"
          description: "{{ $value }} messages in DLQ. Failed requests are accumulating and need manual review."

      - alert: DLQMessagesThresholdExceeded
        expr: sum(api_gateway_dlq_messages_total) > 50
        for: 2m
        labels:
          severity: critical
          component: api_gateway
          pattern: dlq
        annotations:
          summary: "CRITICAL: Dead Letter Queue threshold exceeded"
          description: "{{ $value }} messages in DLQ. High volume of failures detected. Immediate investigation required."
          runbook_url: "https://docs.songnodes.com/runbooks/dlq-overflow"

      # API Error Rate Alerts
      - alert: HighAPIErrorRate
        expr: |
          (
            sum(rate(api_gateway_errors_total[5m])) by (provider) /
            sum(rate(api_gateway_requests_total[5m])) by (provider)
          ) > 0.1
        for: 5m
        labels:
          severity: warning
          component: api_gateway
          pattern: errors
        annotations:
          summary: "High error rate for {{ $labels.provider }}"
          description: "{{ $labels.provider }} error rate is {{ $value | humanizePercentage }}. Normal is <5%. Check provider API status and credentials."

      - alert: CriticalAPIErrorRate
        expr: |
          (
            sum(rate(api_gateway_errors_total[5m])) by (provider) /
            sum(rate(api_gateway_requests_total[5m])) by (provider)
          ) > 0.5
        for: 2m
        labels:
          severity: critical
          component: api_gateway
          pattern: errors
        annotations:
          summary: "CRITICAL: {{ $labels.provider }} error rate exceeds 50%"
          description: "{{ $labels.provider }} is failing {{ $value | humanizePercentage }} of requests. Immediate action required."
          runbook_url: "https://docs.songnodes.com/runbooks/critical-api-errors"

      # Retry Storm Detection
      - alert: RetryStormDetected
        expr: |
          sum(rate(api_gateway_retry_attempts_total{attempt=~"[3-9]|[1-9][0-9]+"}[5m])) by (provider) > 1
        for: 3m
        labels:
          severity: warning
          component: api_gateway
          pattern: retry
        annotations:
          summary: "Retry storm detected for {{ $labels.provider }}"
          description: "{{ $labels.provider }} is experiencing high retry attempts ({{ $value }} retries/sec beyond attempt 3). May indicate persistent upstream issues."

      # Timeout Alerts
      - alert: HighTimeoutRate
        expr: |
          (
            sum(rate(api_gateway_timeout_errors_total[5m])) by (provider) /
            sum(rate(api_gateway_requests_total[5m])) by (provider)
          ) > 0.05
        for: 5m
        labels:
          severity: warning
          component: api_gateway
          pattern: timeout
        annotations:
          summary: "High timeout rate for {{ $labels.provider }}"
          description: "{{ $labels.provider }} timeout rate is {{ $value | humanizePercentage }}. Provider may be experiencing latency issues."

  - name: api_gateway_performance
    interval: 1m
    rules:
      # Latency Alerts
      - alert: HighAPILatency
        expr: |
          histogram_quantile(0.95,
            sum(rate(api_gateway_request_duration_seconds_bucket[5m])) by (le, provider)
          ) > 5
        for: 5m
        labels:
          severity: warning
          component: api_gateway
          pattern: latency
        annotations:
          summary: "High API latency for {{ $labels.provider }}"
          description: "{{ $labels.provider }} p95 latency is {{ $value }}s (threshold: 5s). Check provider performance and network."

      - alert: CacheOperationSlow
        expr: |
          histogram_quantile(0.95,
            sum(rate(api_gateway_cache_operation_duration_seconds_bucket{operation="get"}[5m])) by (le)
          ) > 0.1
        for: 5m
        labels:
          severity: warning
          component: api_gateway
          pattern: cache
        annotations:
          summary: "Cache GET operations are slow"
          description: "Redis cache p95 GET latency is {{ $value }}s (threshold: 0.1s). Check Redis health and network."

  - name: api_gateway_availability
    interval: 1m
    rules:
      # Enrichment Success Rate
      - alert: EnrichmentSuccessRateLow
        expr: |
          (
            sum(rate(enrichment_api_calls_total{status="success"}[5m])) /
            sum(rate(enrichment_api_calls_total[5m]))
          ) < 0.9
        for: 10m
        labels:
          severity: warning
          component: enrichment_pipeline
          pattern: availability
        annotations:
          summary: "Enrichment pipeline success rate below 90%"
          description: "Overall enrichment success rate is {{ $value | humanizePercentage }}. Expected >95%. Check API Gateway health and provider availability."

      - alert: EnrichmentSuccessRateCritical
        expr: |
          (
            sum(rate(enrichment_api_calls_total{status="success"}[5m])) /
            sum(rate(enrichment_api_calls_total[5m]))
          ) < 0.7
        for: 5m
        labels:
          severity: critical
          component: enrichment_pipeline
          pattern: availability
        annotations:
          summary: "CRITICAL: Enrichment pipeline success rate below 70%"
          description: "Enrichment success rate is {{ $value | humanizePercentage }}. Major degradation in service. Immediate investigation required."
          runbook_url: "https://docs.songnodes.com/runbooks/enrichment-degradation"
