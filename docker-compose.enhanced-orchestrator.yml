version: '3.8'

# Enhanced Scraper Orchestrator with Automated Scheduling
# This overlay enables the enhanced orchestrator with robots.txt compliance
# and intelligent scheduling based on domain health metrics.
#
# Usage:
#   docker-compose -f docker-compose.yml -f docker-compose.enhanced-orchestrator.yml up -d
#
# Features:
# - Automatic robots.txt parsing and compliance
# - Adaptive rate limiting based on server response
# - Intelligent scheduling with domain health tracking
# - Comprehensive monitoring and metrics

services:
  scraper-orchestrator:
    build:
      context: ./services/scraper-orchestrator
      dockerfile: Dockerfile.enhanced
    image: songnodes-enhanced-orchestrator:latest
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      # Scraper service URLs
      - SCRAPER_1001TRACKLISTS_URL=http://scraper-1001tracklists:8011
      - SCRAPER_MIXESDB_URL=http://scraper-mixesdb:8012
      - SCRAPER_SETLISTFM_URL=http://scraper-setlistfm:8013
      - SCRAPER_REDDIT_URL=http://scraper-reddit:8014
      # Enhanced orchestrator settings
      - ENABLE_ROBOTS_COMPLIANCE=true
      - ENABLE_ADAPTIVE_SCHEDULING=true
      - DEFAULT_MIN_INTERVAL=3600  # 1 hour minimum between scrapes
      - DEFAULT_MAX_INTERVAL=86400  # 24 hours maximum between scrapes
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.orchestrator.rule=Host(`orchestrator.localhost`)"
      - "traefik.http.services.orchestrator.loadbalancer.server.port=8001"
      - "com.songnodes.component=orchestrator"
      - "com.songnodes.version=enhanced"