global:
  # SMTP disabled for development environment - no email server available
  # smtp_smarthost: 'localhost:587'
  # smtp_from: 'songnodes-alerts@localhost'
  # smtp_auth_username: ''
  # smtp_auth_password: ''

  # Default notification templates
  resolve_timeout: 5m

# Routing configuration
route:
  group_by: ['alertname', 'severity', 'component']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  receiver: 'default-receiver'

  # Routing tree for different alert types
  routes:
    # Critical alerts - immediate notification
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 10s
      repeat_interval: 30m

    # Enrichment pipeline alerts
    - match:
        component: enrichment_pipeline
      receiver: 'enrichment-team'
      group_by: ['alertname', 'provider', 'field_category']
      group_interval: 5m
      routes:
        # Critical enrichment issues
        - match:
            severity: critical
          receiver: 'critical-alerts'
          group_wait: 10s
        # Waterfall efficiency warnings
        - match:
            category: efficiency
          receiver: 'enrichment-team'
          group_interval: 10m

    # API Gateway and resilience alerts
    - match:
        component: api_gateway
      receiver: 'api-team'
      group_by: ['alertname', 'provider']
      group_interval: 3m
      routes:
        # Circuit breaker events
        - match:
            category: resilience
          receiver: 'api-team'
          group_wait: 30s

    # DLQ management alerts
    - match:
        component: dlq_manager
      receiver: 'dlq-team'
      group_by: ['alertname', 'queue_name']
      group_interval: 5m
      routes:
        # Critical DLQ depth
        - match:
            severity: critical
          receiver: 'critical-alerts'
          group_wait: 10s

    # Medallion architecture alerts
    - match_re:
        alertname: '(BronzeToSilverLagHigh|SilverToGoldLagHigh|SilverDataQualityLow)'
      receiver: 'data-engineering-team'
      group_by: ['alertname', 'layer']
      group_interval: 10m

    # Infrastructure alerts
    - match:
        component: infrastructure
      receiver: 'infrastructure-team'
      group_interval: 2m

    # Data platform alerts
    - match:
        team: data-platform
      receiver: 'data-platform-team'
      group_interval: 3m

    # Performance alerts (less urgent)
    - match:
        component: api
      receiver: 'backend-team'
      group_interval: 10m

    # Cost monitoring alerts
    - match:
        category: cost
      receiver: 'finance-team'
      group_interval: 30m
      repeat_interval: 12h

    # Data quality alerts
    - match:
        category: data_quality
      receiver: 'data-quality-team'
      group_interval: 15m

    # Scraper health and performance alerts
    - match:
        component: scraper
      receiver: 'scraper-team'
      group_by: ['alertname', 'scraper_name', 'severity']
      group_wait: 1m
      repeat_interval: 2h

    # Scraper extraction failures
    - match:
        component: extraction
      receiver: 'extraction-team'
      group_by: ['alertname', 'scraper_name', 'failure_reason']
      group_wait: 1m
      repeat_interval: 2h

    # Service down alerts - immediate notification
    - match:
        alertname: ServiceDown
      receiver: 'service-down-team'
      group_wait: 10s
      repeat_interval: 10m

    # Database alerts
    - match:
        component: database
      receiver: 'database-team'
      group_by: ['alertname', 'severity']
      group_wait: 30s
      repeat_interval: 30m

    # Performance alerts
    - match:
        component: performance
      receiver: 'performance-team'
      group_by: ['alertname', 'service']
      group_interval: 5m
      repeat_interval: 2h

    # Warning alerts (less urgent)
    - match:
        severity: warning
      receiver: 'warning-alerts'
      group_wait: 2m
      group_interval: 10m
      repeat_interval: 6h

    # Info level alerts (batched)
    - match:
        severity: info
      receiver: 'info-alerts'
      group_interval: 15m
      repeat_interval: 12h

# ===============================================================================
# RECEIVERS - Slack Integration Enabled
# ===============================================================================
# Configure SLACK_WEBHOOK_URL in .env file to enable notifications
# Supports channel-specific webhooks for optimal routing
receivers:
  # ---------------------------------------------------------------------------
  # Default receiver (fallback for unmatched alerts)
  # ---------------------------------------------------------------------------
  - name: 'default-receiver'
    slack_configs:
      - channel: '#songnodes-alerts'
        username: 'Alertmanager'
        icon_emoji: ':bell:'
        title: '{{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Severity:* {{ .Labels.severity }}
          {{ if .Labels.component }}*Component:* {{ .Labels.component }}{{ end }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}'

  # ---------------------------------------------------------------------------
  # Critical alerts - multiple channels with @channel mention
  # ---------------------------------------------------------------------------
  - name: 'critical-alerts'
    slack_configs:
      - channel: '#songnodes-critical'
        username: 'Critical Alert'
        icon_emoji: ':rotating_light:'
        color: 'danger'
        title: ':rotating_light: CRITICAL: {{ .GroupLabels.alertname }}'
        text: |
          <!channel> *CRITICAL ALERT FIRED*

          {{ range .Alerts }}
          ---
          *Alert:* {{ .Annotations.summary }}
          *Priority:* {{ .Labels.priority | default "P1" }}
          *Team:* {{ .Labels.team | default "platform" }}
          {{ if .Labels.component }}*Component:* {{ .Labels.component }}{{ end }}

          *Description:*
          {{ .Annotations.description }}

          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ if .Annotations.dashboard_url }}*Dashboard:* {{ .Annotations.dashboard_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_CRITICAL:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # Enrichment pipeline team
  # ---------------------------------------------------------------------------
  - name: 'enrichment-team'
    slack_configs:
      - channel: '#songnodes-enrichment'
        username: 'Enrichment Monitor'
        icon_emoji: ':sparkles:'
        title: 'Enrichment Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          {{ if .Labels.provider }}*Provider:* {{ .Labels.provider }}{{ end }}
          {{ if .Labels.field_category }}*Field Category:* {{ .Labels.field_category }}{{ end }}
          *Description:* {{ .Annotations.description }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_ENRICHMENT:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # API Gateway team
  # ---------------------------------------------------------------------------
  - name: 'api-team'
    slack_configs:
      - channel: '#songnodes-api-gateway'
        username: 'API Gateway Monitor'
        icon_emoji: ':electric_plug:'
        title: 'API Gateway Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          {{ if .Labels.provider }}*Provider:* {{ .Labels.provider }}{{ end }}
          {{ if .Labels.category }}*Category:* {{ .Labels.category }}{{ end }}
          *Description:* {{ .Annotations.description }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_API_GATEWAY:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # DLQ management team
  # ---------------------------------------------------------------------------
  - name: 'dlq-team'
    slack_configs:
      - channel: '#songnodes-dlq'
        username: 'DLQ Monitor'
        icon_emoji: ':outbox_tray:'
        title: 'DLQ Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          {{ if .Labels.queue_name }}*Queue:* {{ .Labels.queue_name }}{{ end }}
          *Description:* {{ .Annotations.description }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_DLQ:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # Data engineering team (Medallion architecture)
  # ---------------------------------------------------------------------------
  - name: 'data-engineering-team'
    slack_configs:
      - channel: '#songnodes-data-engineering'
        username: 'Data Engineering Monitor'
        icon_emoji: ':building_construction:'
        title: 'Data Pipeline Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          {{ if .Labels.layer }}*Layer:* {{ .Labels.layer }}{{ end }}
          *Description:* {{ .Annotations.description }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_DATA_ENG:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # Finance team (cost alerts)
  # ---------------------------------------------------------------------------
  - name: 'finance-team'
    slack_configs:
      - channel: '#songnodes-cost-alerts'
        username: 'Cost Monitor'
        icon_emoji: ':moneybag:'
        title: 'Cost Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_FINANCE:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # Data quality team
  # ---------------------------------------------------------------------------
  - name: 'data-quality-team'
    slack_configs:
      - channel: '#songnodes-data-quality'
        username: 'Data Quality Monitor'
        icon_emoji: ':bar_chart:'
        title: 'Data Quality Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_DATA_QUALITY:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # Infrastructure team notifications
  # ---------------------------------------------------------------------------
  - name: 'infrastructure-team'
    slack_configs:
      - channel: '#songnodes-infrastructure'
        username: 'Infrastructure Monitor'
        icon_emoji: ':gear:'
        title: 'Infrastructure Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Severity:* {{ .Labels.severity }}
          *Description:* {{ .Annotations.description }}
          {{ if .Labels.instance }}*Instance:* {{ .Labels.instance }}{{ end }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_INFRA:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # Data platform team notifications
  # ---------------------------------------------------------------------------
  - name: 'data-platform-team'
    slack_configs:
      - channel: '#songnodes-data-platform'
        username: 'Data Platform Monitor'
        icon_emoji: ':floppy_disk:'
        title: 'Data Platform Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_DATA_PLATFORM:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # Backend team for API issues
  # ---------------------------------------------------------------------------
  - name: 'backend-team'
    slack_configs:
      - channel: '#songnodes-backend'
        username: 'Backend Monitor'
        icon_emoji: ':computer:'
        title: 'Backend Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_BACKEND:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # Scraper team (scraper health and performance)
  # ---------------------------------------------------------------------------
  - name: 'scraper-team'
    slack_configs:
      - channel: '#songnodes-scraper-alerts'
        username: 'Scraper Monitor'
        icon_emoji: ':spider_web:'
        title: 'Scraper Alert: {{ .GroupLabels.alertname }}'
        text: |
          *Scraper:* {{ .GroupLabels.scraper_name | default "Unknown" }}
          *Severity:* {{ .GroupLabels.severity }}

          {{ range .Alerts }}
          ---
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          {{ if .Labels.source }}*Source:* {{ .Labels.source }}{{ end }}
          {{ if .Labels.container_id }}*Container:* {{ .Labels.container_id }}{{ end }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_SCRAPERS:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # Extraction team (scraping failures and extraction issues)
  # ---------------------------------------------------------------------------
  - name: 'extraction-team'
    slack_configs:
      - channel: '#songnodes-extraction-alerts'
        username: 'Extraction Monitor'
        icon_emoji: ':mag:'
        title: 'Extraction Alert: {{ .GroupLabels.alertname }}'
        text: |
          *Scraper:* {{ .GroupLabels.scraper_name | default "Unknown" }}
          {{ if .GroupLabels.failure_reason }}*Failure Reason:* {{ .GroupLabels.failure_reason }}{{ end }}

          {{ range .Alerts }}
          ---
          *Summary:* {{ .Annotations.summary }}
          {{ if .Labels.url_pattern }}*URL Pattern:* {{ .Labels.url_pattern }}{{ end }}
          {{ if .Labels.extraction_type }}*Extraction Type:* {{ .Labels.extraction_type }}{{ end }}

          *Description:*
          {{ .Annotations.description }}

          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_EXTRACTION:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # Service down team
  # ---------------------------------------------------------------------------
  - name: 'service-down-team'
    slack_configs:
      - channel: '#songnodes-service-down'
        username: 'Service Monitor'
        icon_emoji: ':x:'
        color: 'danger'
        title: ':x: SERVICE DOWN: {{ .GroupLabels.alertname }}'
        text: |
          <!here> *SERVICE DOWN DETECTED*

          {{ range .Alerts }}
          *Service:* {{ .Labels.job }}
          *Instance:* {{ .Labels.instance }}
          *Description:* {{ .Annotations.description }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_SERVICE_DOWN:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # Database team
  # ---------------------------------------------------------------------------
  - name: 'database-team'
    slack_configs:
      - channel: '#songnodes-database-alerts'
        username: 'Database Monitor'
        icon_emoji: ':floppy_disk:'
        title: 'Database Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Severity:* {{ .Labels.severity }}
          *Description:* {{ .Annotations.description }}
          {{ if .Labels.pool_type }}*Pool Type:* {{ .Labels.pool_type }}{{ end }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_DATABASE:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # Performance team
  # ---------------------------------------------------------------------------
  - name: 'performance-team'
    slack_configs:
      - channel: '#songnodes-performance'
        username: 'Performance Monitor'
        icon_emoji: ':chart_with_upwards_trend:'
        title: 'Performance Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          {{ if .Labels.service }}*Service:* {{ .Labels.service }}{{ end }}
          {{ if .Annotations.threshold }}*Threshold:* {{ .Annotations.threshold }}{{ end }}
          {{ if .Annotations.current_value }}*Current Value:* {{ .Annotations.current_value }}{{ end }}
          *Description:* {{ .Annotations.description }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_PERFORMANCE:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # Warning alerts
  # ---------------------------------------------------------------------------
  - name: 'warning-alerts'
    slack_configs:
      - channel: '#songnodes-warnings'
        username: 'Warning Monitor'
        icon_emoji: ':warning:'
        color: 'warning'
        title: ':warning: Warning: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          {{ if .Labels.component }}*Component:* {{ .Labels.component }}{{ end }}
          *Description:* {{ .Annotations.description }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_WARNINGS:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

  # ---------------------------------------------------------------------------
  # Info alerts - batched summary
  # ---------------------------------------------------------------------------
  - name: 'info-alerts'
    slack_configs:
      - channel: '#songnodes-info'
        username: 'Info Monitor'
        icon_emoji: ':information_source:'
        color: 'good'
        title: ':information_source: Info: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          {{ if .Labels.component }}*Component:* {{ .Labels.component }}{{ end }}
          *Description:* {{ .Annotations.description }}
          {{ end }}
        send_resolved: true
        api_url: '${SLACK_WEBHOOK_URL_INFO:-${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER_REPLACE_ME}}'

# Inhibition rules to reduce noise
inhibit_rules:
  # If service is down, don't alert on high latency for same service
  - source_match:
      alertname: ServiceDown
    target_match:
      alertname: APIHighLatency
    equal: ['instance']

  # If there's a critical database issue, don't alert on query latency
  - source_match:
      severity: critical
      component: database
    target_match:
      alertname: DatabaseHighLatency
    equal: ['instance']

  # If scraper has high error rate, don't alert on low activity
  - source_match:
      alertname: ScraperHighErrorRate
    target_match:
      alertname: ScraperLowActivity
    equal: ['scraper']

  # Circuit breaker inhibitions
  # If circuit breaker is open, don't alert on API errors for same provider
  - source_match:
      alertname: CircuitBreakerOpen
    target_match_re:
      alertname: '(EnrichmentAPIHighErrorRate|ProviderResponseTimeSlow)'
    equal: ['provider']

  # If circuit breaker is flapping, suppress related alerts
  - source_match:
      alertname: CircuitBreakerFlapping
    target_match:
      alertname: CircuitBreakerOpen
    equal: ['provider']

  # DLQ inhibitions
  # If DLQ depth is critical, don't alert on high depth warning
  - source_match:
      alertname: DLQDepthCritical
    target_match:
      alertname: DLQDepthHigh
    equal: ['queue']

  # If DLQ is full, don't alert on replay failures
  - source_match:
      alertname: DLQDepthCritical
    target_match:
      alertname: DLQReplayFailureRateHigh
    equal: ['queue']

  # Enrichment pipeline inhibitions
  # If provider is completely failing, suppress related warnings
  - source_match:
      alertname: WaterfallProviderFailure
    target_match_re:
      alertname: '(WaterfallFallbackRateHigh|EnrichmentAPIHighErrorRate)'
    equal: ['provider']

  # If data quality is critically low, suppress completeness warnings
  - source_match:
      alertname: SilverDataQualityLow
      severity: critical
    target_match:
      alertname: EnrichmentCompletenessCritical
    equal: ['layer']

  # If Bronze->Silver lag is critical, suppress Gold materialization lag
  - source_match:
      alertname: BronzeToSilverLagHigh
      severity: critical
    target_match:
      alertname: SilverToGoldLagHigh

# Templates for custom formatting
templates:
  - '/etc/alertmanager/templates/*.tmpl'