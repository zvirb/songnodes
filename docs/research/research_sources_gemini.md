A Strategic Framework for Acquiring and Enriching DJ Setlist Data for Co-occurrence AnalysisExecutive SummaryThis report presents a comprehensive, strategic framework for the large-scale acquisition and enrichment of DJ setlist data. The primary objective is to construct a robust database suitable for analyzing track co-occurrence relationships, thereby modeling the intricate art of DJ curation. The methodology detailed herein prioritizes free, programmatically accessible data sources and outlines a multi-layered approach to data gathering and processing.The acquisition of raw setlist data necessitates a hybrid strategy, combining the use of public APIs with sophisticated web scraping techniques. An analysis of broad-spectrum platforms such as SoundCloud, Mixcloud, and YouTube reveals them to be high-volume but structurally inconsistent sources, requiring significant investment in Natural Language Processing (NLP) for data extraction. Conversely, niche, genre-specific communities and forums offer higher-quality, curated data at the cost of developing multiple, specialized parsers.For metadata enrichment, this report proposes a "waterfall" model—a sequential, multi-API pipeline designed to maximize data accuracy and minimize redundant calls. This strategy leverages the unique strengths of foundational databases: Spotify for its extensive catalog and invaluable audio-feature data; MusicBrainz for its rigorous entity identification and relationship mapping; and Discogs for its unparalleled depth in release-specific information, particularly for electronic and physical media.Finally, to enable a deeper, more nuanced analysis of DJ curation, this framework extends beyond standard metadata to include advanced sonic, harmonic, structural, and contextual metrics. It details methods for acquiring audio features like energy and danceability via the Spotify API, deriving harmonic mixing keys (Camelot notation), and outlines a process for calculating structural elements such as intro/outro durations through audio signal processing with libraries like librosa. Furthermore, it proposes the development of a novel "DJ Popularity Score," an internally derived metric to quantify a track's influence specifically within the professional DJ community. The report concludes with a recommended phased implementation plan to manage technical complexity and ensure the scalable development of the data pipeline.Section 1: Sources for Raw DJ Setlist DataThe foundation of any setlist analysis project is a large and diverse corpus of raw track co-occurrence data. This section provides a detailed evaluation of potential data sources, moving beyond established archives to identify and assess a portfolio of platforms that, when combined, offer extensive coverage across multiple genres. The core strategy is one of data source diversification to mitigate the weaknesses of any single platform and to maximize both the volume and breadth of the collected data.1.1 Broad-Spectrum Platforms for Multi-Genre AnalysisLarge-scale media hosting platforms represent the most significant sources of raw data by volume. While they are not purpose-built for setlist archiving, the sheer quantity of user-uploaded DJ mixes makes them indispensable. However, their unstructured nature presents the primary technical challenge.1.1.1 SoundCloud: The Ubiquitous but Unstructured SourceData Profile: SoundCloud serves as a vast repository for millions of user-uploaded DJ mixes, radio shows, and podcasts. Its low barrier to entry makes it a primary distribution channel for DJs of all levels. Tracklists, when provided, are almost exclusively located as unstructured free text within the track's description field.Data Acquisition Strategy: The official SoundCloud API is not suitable for the primary task of setlist extraction. An analysis of its documentation reveals that its endpoints are principally designed for user-centric actions like uploading, managing playlists, and retrieving metadata for individual tracks.1 The GET /tracks/{track_id} endpoint can retrieve a mix's description, but this text then requires extensive post-processing.5 For retrieving large numbers of tracks from a user, pagination is supported via the linked_partitioning=1 parameter.6Given these API limitations, web scraping emerges as the necessary and primary method for acquiring tracklist data at scale. The viability of this approach is confirmed by the existence of numerous open-source libraries (e.g., soundscrape 7) and commercial scraping services 9 that target the platform. A custom-built solution would involve making an HTTP request to a mix's URL, extracting the HTML content, and using a parsing library (e.g., BeautifulSoup for Python) to isolate the description text.Potential Challenges: The most significant challenge is the complete lack of a standardized tracklist format. Descriptions can range from neatly timestamped lists to simple paragraphs of text. This variability necessitates the development of a sophisticated and resilient parser, likely leveraging Natural Language Processing (NLP) and regular expressions, to identify patterns corresponding to timestamps, artist names, and track titles. Furthermore, aggressive, large-scale scraping will inevitably encounter rate limiting, identifiable by HTTP 429 Too Many Requests status codes, requiring the implementation of a robust proxy rotation and request throttling strategy.2Strategic Implications: The discrepancy between the API's functionality and the data present on the website indicates that SoundCloud does not expose structured setlist data, even if it were available internally. Consequently, the data acquisition module for SoundCloud must be architected as an NLP-driven text extraction and interpretation system rather than a straightforward data retrieval client. The success of this module is directly dependent on the intelligence of its parser.1.1.2 Mixcloud: The Structured but Guarded PlatformData Profile: Mixcloud is a platform dedicated to long-form audio, making it a high-quality source for DJ sets and radio shows. Historically, it was known for its support of structured, timestamped tracklists that were clearly visible to users.Data Acquisition Strategy: The official Mixcloud API, while providing endpoints for user profiles and searching for mixes (referred to as "cloudcasts") via /search/?q={query}&type=cloudcast, does not offer a documented public endpoint for retrieving the structured tracklist of a mix.11 The API documentation confirms that tracklist data is a component of the upload process (via fields like sections-X-artist and sections-X-song), but this structured data is not exposed for public retrieval.11This intentional omission points toward a scraping-first strategy. While Mixcloud has made tracklists less prominent on its user interface, the underlying data is often still delivered to the client's browser. The existence of community-built tools like the "Mixcloud Tracklist Enabler" bookmarklet, which re-enables the visibility of these lists, is strong evidence of this practice.12 Therefore, an effective scraping strategy should not focus on parsing the rendered HTML that a user sees, as this may contain no tracklist. Instead, the approach should be to inspect the initial HTML page source for embedded JSON data or to monitor the network requests made by the page upon loading to intercept the raw tracklist data before it is programmatically hidden by the site's JavaScript. This method is significantly more efficient and less fragile than relying on a full headless browser.Potential Challenges: Mixcloud's terms of service explicitly prohibit the downloading of audio files 13, and the active obfuscation of tracklist data signals a potential for evolving anti-scraping countermeasures. The API is rate-limited, and exceeding this limit will trigger a 403 Forbidden error that includes a Retry-After header indicating the required cool-down period.11Strategic Implications: The platform's architecture—accepting structured tracklists on upload but hiding them on retrieval—suggests a deliberate policy, likely influenced by music licensing and rights-holder agreements. For a data acquisition project, this means any engagement with Mixcloud will be a continuous effort of reverse-engineering. The most sustainable scraping technique is one that mimics a data-consuming client application rather than a human user, focusing on the underlying data payloads instead of the visual presentation.1.1.3 YouTube: The Video-First Data GoldmineData Profile: As the world's largest video platform, YouTube hosts an unparalleled volume of DJ sets, from official festival recordings to user-uploaded mixes. Tracklists are not a native feature and are almost always provided by the uploader or the community as unstructured text within the video's description or in the comments section.14 The quality, completeness, and format of these tracklists vary dramatically.Data Acquisition Strategy: The YouTube Data API v3 is the essential tool for accessing this data. A robust workflow would consist of three main stages:Discovery: Use the search.list endpoint to identify relevant DJ channels (e.g., Boiler Room, Defected Records, HÖR Berlin) and individual set videos based on keyword queries.Description Extraction: For each identified video, use the videos.list endpoint with part=snippet to retrieve the full video description, which is the most common location for a tracklist.15Comment Extraction: Use the commentThreads.list endpoint to retrieve top-level comments and their replies. It is common for uploaders to post the tracklist in a "pinned" comment or for community members to collaboratively identify tracks.16The core technical task, similar to SoundCloud, is parsing the extracted free text. The common use of timestamps (e.g., `` or MM:SS) provides a crucial structural anchor for parsing algorithms. The existence of third-party services like Set2Tracks, which automatically convert YouTube DJ sets into tracklists, serves as a proof-of-concept for the feasibility of this automated approach.17Potential Challenges: The YouTube Data API operates on a quota system, and extensive, repeated queries can exhaust the daily quota quickly, necessitating efficient and targeted API call strategies. The extreme diversity of tracklist formats demands a highly flexible, heuristic-based parser capable of handling numerous edge cases.Strategic Implications: The YouTube API provides reliable access to the containers of text (descriptions and comments), but the content within is chaotic. The community has organically developed conventions for sharing this information, creating a user-driven solution to a platform deficiency. For this project, the YouTube data module must be a two-part system: a disciplined API client for fetching the raw text, and a sophisticated NLP engine for extracting structured data from it. The value derived from YouTube is directly proportional to the intelligence and adaptability of this parsing engine.1.2 Genre-Specific Communities and Niche SourcesTo complement the high-volume, low-structure data from broad-spectrum platforms, a targeted acquisition strategy focused on genre-specific communities is essential. These sources often provide higher-fidelity data curated by experts and enthusiasts, making them invaluable for training parsing models and ensuring deep coverage of specific musical styles.1.2.1 Resident Advisor (RA): The Hub for Electronic MusicData Profile: Resident Advisor (RA) is a globally recognized authority in the electronic music scene, offering comprehensive data on events, venues, artists, and labels.18 While it is not primarily a setlist archive, its rich, interconnected data provides essential context for understanding the relationships between DJs, events, and music.Data Acquisition Strategy: RA does not provide an official, public API for data access. While commercial, scraper-based "APIs" are available through platforms like Apify, they primarily focus on extracting artist and event data, not setlists.19The most effective and efficient strategy for scraping RA involves exploiting its underlying web framework. Community analysis has revealed that RA is built using Next.js, a popular JavaScript framework.21 A key feature of many Next.js sites is the embedding of a page's initial state and data as a large JSON object within a <script id="__NEXT_DATA__"> tag in the raw HTML source. This is a critical discovery. It means that instead of resorting to slow and brittle methods like running a full headless browser (e.g., Selenium or Playwright) to render the page and parse HTML elements 22, a scraper can be built using a simple HTTP client (e.g., Python's requests library). The process becomes: fetch the HTML, locate the __NEXT_DATA__ script tag, extract its JSON content, and parse it directly. This method is orders of magnitude faster, consumes fewer resources, and is often more resilient to minor UI changes.Potential Challenges: The structure of the __NEXT_DATA__ JSON object is internal to RA's application and is not a public contract; it can and will change without notice during site updates, requiring periodic maintenance of the scraper's parsing logic. Direct setlist data is sparse on RA, so the primary value lies in building a contextual graph of artist-event relationships.Strategic Implications: The choice between a naive scraping approach (simulating a browser) and an informed one (parsing embedded data objects) represents a fundamental difference in engineering efficiency. For modern, JavaScript-driven websites, the initial reconnaissance phase for any scraping task should always include inspecting the raw page source for such embedded JSON payloads. This "look for the data object" pattern is a powerful heuristic that can dramatically reduce development time and improve scraper robustness. RA should be treated as a primary source for contextual metadata, not direct setlists.1.2.2 Forum and Community MiningData Profile: For decades, dedicated online forums have served as the primary hubs for passionate music communities to discuss events and collaboratively create tracklists. This data is often highly accurate, containing IDs for obscure or unreleased tracks that are unavailable elsewhere.Source Identification & Strategy:Drum & Bass: The rolldabeats.com/forum is a cornerstone of the online D&B community, with a dedicated "Tracklists" section containing thousands of user-submitted setlists from radio shows and live events dating back years.23 A custom scraper would need to navigate the forum's pagination, parse topic titles to identify the mix details (DJ, event, date), and then parse the unstructured text within the forum posts themselves.Trance: Websites like trancealliance.com and tranceforum.info have historically been important sources.24 While TranceAlliance has largely migrated its real-time community to Discord and Twitch, its website still contains archived tracklists and posts new ones.24General Electronic Music (Reddit): Genre-specific subreddits are active and valuable sources. Communities like r/House, r/techno, r/DnB, and r/electronicmusic are rich with track ID requests, mix discussions, and full tracklist posts.26 Some, like r/House, enforce a strict submission format of "Artist - Title," which makes the data exceptionally clean and easy to parse programmatically.26 The official Reddit API provides a structured and reliable method for systematically fetching submissions and comments from these communities, making it a prime target for automated data collection.Potential Challenges: Each forum or website has a unique HTML structure, necessitating the development and maintenance of a separate, custom parser for each target source. The data, being user-submitted, can contain typos, abbreviations, and inconsistencies that require a sophisticated data cleaning and entity resolution pipeline to normalize artist and track names.Strategic Implications: The data from these niche communities can be considered "artisanal"—it is often of higher quality and contains more obscure information than that found on large platforms. However, it lacks a standardized schema. This shifts the engineering challenge from overcoming anti-scraping measures to implementing robust data cleaning, normalization, and entity resolution processes. For example, the system must be able to recognize that "DJ Hype," "Hype," and "dj hype" all refer to the same canonical artist entity.1.2.3 Hip-Hop Setlist ReconstructionData Profile: The culture of documenting and sharing timestamped, linear setlists is less prevalent in many Hip-Hop DJ communities compared to electronic music. Consequently, a different approach is required for data acquisition.Strategy: The focus must shift from "setlist extraction" to "setlist reconstruction." This involves aggregating data from sources that reflect typical track selections for Hip-Hop sets, even if they do not represent a single performance.DJ-Centric Services (Beatsource): Platforms like Beatsource are designed as resources for working DJs. They offer expertly curated playlists for various contexts, such as "Essential Hip-Hop Edits," "Club Opening - Hip-Hop," and "Rap Essentials".29 While Beatsource does not offer a public API, its playlist pages have a relatively simple structure amenable to web scraping.29 The tracks within these playlists represent strong co-occurrence signals.Community Discussions (Reddit): Threads on subreddits like r/DJs and r/Beatmatch frequently feature discussions where DJs share their "go-to" tracks, "crowd pleasers," and partial setlists for Hip-Hop nights.30 Mining this text using the Reddit API can yield a probabilistic graph of track relationships.Potential Challenges: This methodology does not produce deterministic, time-ordered setlists. Instead, it generates a probabilistic model of co-occurrence—it answers the question "what tracks are likely to be played together in a Hip-Hop set?" rather than "what tracks were played in this specific set?" This distinction must be accounted for in the database schema and subsequent analysis.Strategic Implications: The absence of formal setlists on platforms like setlist.fm (where forum discussions acknowledge the difficulty of logging DJ sets 33) represents a data gap that requires a creative solution. DJ resource platforms and community forums provide a powerful alternative source of information. This necessitates a flexible definition of a "setlist" within the project's data model. For electronic music, a setlist can be modeled as a time-series of tracks. For genres like Hip-Hop, it may be more effectively modeled as a "bag of tracks" or a weighted graph of co-occurrence probabilities derived from these curated and community-sourced collections.Table 1.1: Comparative Analysis of Raw Setlist Data SourcesSourcePrimary Genre(s)Data TypeTracklist FormatRecommended Access MethodKey ChallengeEst. Data QualityEst. Data VolumeSoundCloudMulti-GenreUser-Submitted MixesUnstructured TextWeb Scraping (Complex)NLP Parsing, Rate LimitsLow-MediumVery HighMixcloudMulti-GenreUser-Submitted MixesHidden JSONWeb Scraping (Complex)Anti-Scraping, ObfuscationMedium-HighHighYouTubeMulti-GenreUser-Submitted MixesUnstructured TextAPI + NLP ParsingAPI Quotas, NLP ComplexityLow-MediumVery HighResident AdvisorElectronicEvent/Artist DataEmbedded JSONWeb Scraping (Simple)Data is Contextual, Not SetlistsHighMediumrolldabeats.comDrum & BassForum PostsStructured Forum TextWeb Scraping (Medium)Custom Parser, Data CleaningHighMediumReddit (e.g., r/House)Genre-SpecificForum PostsStandardized TitlesAPIVaries by SubredditMedium-HighHighBeatsourceHip-Hop, Open-FormatCurated PlaylistsStructured HTMLWeb Scraping (Simple)No API, Reconstructive DataHighMediumSection 2: Sources for Track Metadata EnrichmentOnce raw setlist data (consisting primarily of artist and title strings) has been acquired, the next critical phase is enrichment. This process involves augmenting the raw data with a comprehensive and standardized set of metadata from authoritative external databases. This section details a strategic "waterfall" pipeline that queries multiple APIs in a specific sequence to maximize accuracy, coverage, and efficiency.2.1 A Comparative Analysis of Primary Metadata ProvidersNo single API can provide all the required metadata. Each major provider has distinct strengths and weaknesses, and understanding these is key to designing an effective enrichment strategy.2.1.1 MusicBrainz: The Foundational Open Data HubStrengths: MusicBrainz is an open, community-maintained music encyclopedia with a rigorously structured data model designed for disambiguation.34 It is the most reliable and authoritative source for foundational identifiers and relationships. Its key contributions to the schema include the canonical musicbrainz_id for all entities (artists, recordings, releases), International Standard Recording Codes (isrc), and detailed relationship data that can identify remix_of connections. It also excels at tracking artist aliases and the artist's country of origin (country).37API Endpoints: The API is RESTful and well-documented. Key lookup endpoints include /ws/2/artist/<MBID>, /ws/2/recording/<MBID>, and /ws/2/release/<MBID>. A uniquely powerful feature is the inc= query parameter, which allows for the inclusion of linked entities (e.g., inc=artist-rels+isrcs) in a single API call, reducing request latency.34 For initial text-based searches, the /ws/2/<ENTITY_TYPE>?query=... endpoint is essential.38Weaknesses: MusicBrainz does not provide commercial or psychoacoustic data. It lacks audio features such as BPM and key, and does not track popularity metrics or play counts.34 Its genre tagging system, while detailed, can sometimes be overly granular or inconsistently applied for the purposes of broad classification.2.1.2 Spotify: The Mainstream and Audio-Feature PowerhouseStrengths: The Spotify Web API offers excellent coverage of the mainstream and commercially released music catalog. It is the primary and most reliable source for obtaining a track's spotify_id, duration_seconds, release_year (via the associated album object), and isrc (available in the external_ids object).40 However, its most critical and unique contribution is the Audio Features endpoint. This endpoint is the definitive source for psychoacoustic data, providing bpm (as tempo), musical key, and the advanced features discussed in Section 3, such as energy, danceability, and valence.41API Endpoints: The most relevant endpoints for enrichment are GET /v1/tracks/{id} for detailed track metadata 40, GET /v1/artists/{id} for artist information 42, and GET /v1/search for initial lookups by artist and title. The GET /v1/audio-features/{id} endpoint is indispensable for acquiring advanced sonic metrics.41Weaknesses: Spotify's genre information is a significant limitation; genres are applied at the artist level, not the track level, and are often broad, eclectic, or esoteric (e.g., "permanent wave," "melancholia"), making them less useful for specific track classification.42 Its coverage of underground electronic music, vinyl-only releases, or self-released tracks can be incomplete.2.1.3 Discogs: The Crate-Digger's Definitive ResourceStrengths: Discogs possesses an unparalleled database of physical music releases, with a particular focus on electronic music and vinyl. This makes it the superior source for release-specific metadata. It is the best provider for identifying the label and catalog number of a specific release, the release country, and detailed track-level credits that can help confirm remix_of relationships. It provides track duration and often has both genre and more specific style tags at the release level, which are highly valuable.43API Endpoints: The primary data retrieval endpoints are /releases/{release_id} and /masters/{master_id}. The /database/search endpoint is a powerful tool for performing text-based queries using parameters like artist, track title, and release year.44Weaknesses: The Discogs API has been criticized by the developer community for being cumbersome and sometimes returning data that is inconsistent with what is displayed on the main website.47 It does not provide modern identifiers like ISRC, Spotify ID, or MusicBrainz ID directly, making it harder to link to other services. The API rate limit is also relatively strict, capped at 60 requests per minute for authenticated users.442.1.4 Supplementary Sources: Beatport and SoundCloudBeatport: As the leading digital music store for DJs, Beatport is a crucial source for electronic music-specific metadata. It provides highly accurate genre (often at a subgenre level), bpm, and musical key information. However, Beatport does not offer a well-documented or easily accessible public API for this data.48 Accessing this information programmatically often requires using unofficial API wrappers developed by the community or employing direct web scraping techniques.50 It should be considered a high-value but high-difficulty source, best used as a fallback for electronic tracks when other sources fail to provide BPM or key.SoundCloud: The SoundCloud API can provide basic metadata for tracks that are hosted on its platform, including title, artist_name (uploader), duration, and genre.4 Its utility for general enrichment is limited; it should primarily be used to enrich tracks that were originally sourced from SoundCloud itself.2.2 API Capabilities and Schema MappingThe following table provides a clear, at-a-glance summary of which data fields can be reliably sourced from each of the primary metadata providers. This mapping is fundamental to the design of the waterfall enrichment pipeline.Table 2.1: Metadata Schema Fulfillment by APIMetadata FieldMusicBrainzSpotifyDiscogsBeatporttitle✅ Primary✅ Primary✅ Primary✅ Primaryartist_name(s)✅ Primary✅ Primary✅ Primary✅ Primaryrelease_year☑️ Secondary✅ Primary✅ Primary✅ Primarygenre☑️ Secondary❌ (Artist-level)✅ Primary✅ (Best)bpm❌✅ Primary❌✅ (Best)key❌✅ Primary❌✅ (Best)duration_seconds☑️ Secondary✅ Primary☑️ Secondary☑️ Secondaryspotify_id☑️ (Via URL rels)✅ (Canonical)❌❌musicbrainz_id✅ (Canonical)❌❌❌isrc✅ Primary✅ Primary❌❌label☑️ Secondary☑️ Secondary✅ (Best)✅ Primaryremix_of✅ (Best)❌☑️ (Via credits)❌country✅ (Artist origin)❌✅ (Release origin)❌aliases✅ Primary❌☑️ (Via ANVs)❌(✅ = Primary/Reliable Source, ☑️ = Secondary/Available Source, ❌ = Not Available, Best = Often the most accurate source for this field, Canonical = The definitive source for this identifier)2.3 A Strategic Data Enrichment Pipeline: The Waterfall ModelTo efficiently and accurately populate the metadata schema, a sequential querying strategy, or "waterfall model," is required. This approach prioritizes queries based on the availability of high-precision identifiers, falling back to lower-precision text searches only when necessary. This minimizes ambiguity, reduces the total number of API calls, and provides a logical order for resolving data conflicts.The logic of the pipeline is as follows:Step 1: Initialization and Identifier PrioritizationThe process begins with the raw data from a setlist: an artist_name and track_title string. In some cases, a unique identifier like a spotify_id (if the setlist was sourced from a Spotify playlist) or an isrc may already be available.Logic: The pipeline's entry point is determined by the best available identifier.If spotify_id is present, begin at Step 2.If isrc is present (but no spotify_id), begin at Step 3.If only artist_name and track_title are present, begin at Step 4.Step 2: Primary Enrichment via Spotify (High-Precision Start)Trigger: A spotify_id is available.Action: Make a single call to Spotify's GET /v1/tracks/{spotify_id} endpoint.Data Acquired: This one call yields a rich set of core data: canonical title, artist_name(s), duration_seconds, the album's release_year, and, critically, the isrc from the external_ids object.Next Step: With the now-known isrc, proceed to Step 3 to link the track to the MusicBrainz database.Step 3: Foundational Linking via MusicBrainzTrigger: An isrc is known (either from Step 2 or as an initial identifier).Action: Query the MusicBrainz /ws/2/recording?query=isrc:<ISRC_VALUE> endpoint. This provides a highly reliable match.Data Acquired: This step is crucial for data integrity. It provides the canonical musicbrainz_id for the recording and its associated artists. It is also the best source for artist aliases, artist country of origin, and structured remix_of relationships.Next Step: Proceed to Step 5 to fill in any remaining gaps.Step 4: Text-Based Search and Disambiguation (Fuzzy Start)Trigger: Only artist_name and track_title strings are available.Action: This step requires a multi-API search to find a definitive identifier.Query Spotify Search: Use GET /v1/search with the artist and title. The top result is often the correct match. If a confident match is found, extract the spotify_id and isrc, then proceed with the pipeline from Step 2 and Step 3.Query MusicBrainz Search: If Spotify yields no confident result, query the MusicBrainz search endpoint. A successful match provides the musicbrainz_id and potentially an isrc, allowing a jump to Step 3.Challenge: Text-based searches can return multiple results or be ambiguous. This step requires logic to score and select the most likely match based on factors like string similarity (e.g., Levenshtein distance) and popularity.Step 5: Deep Release and Genre Data via Discogs and BeatportTrigger: Core identifiers have been resolved, but release-specific or genre-specific data is missing.Action (Discogs): Using the resolved artist and title, query the Discogs /database/search endpoint. This is the best source to fill in label, detailed genre/style tags, and the country of a specific release.Action (Beatport): If the track is identified as electronic and bpm or key data is still missing from Spotify, perform a final fallback search against the Beatport service (via an unofficial API or scraper). This can provide the most accurate genre, BPM, and key information for dance music.This waterfall architecture ensures that the most reliable data sources are used first and that fuzzy, computationally expensive searches are deferred until all high-precision options have been exhausted. It creates a robust and efficient system for transforming raw, inconsistent strings into a rich, structured, and interconnected metadata database.Section 3: Enhanced Metadata for Advanced DJ Curation AnalysisTo move beyond simple co-occurrence and model the art of DJ curation, it is necessary to acquire metadata that describes the functional and aesthetic properties of a track. Standard catalog data can tell us what was played, but these advanced metrics help explain why and how it was played. This section proposes additional metadata fields and details their acquisition through a combination of specialized APIs and direct audio signal processing.3.1 Quantifying Sonic and Harmonic CharacteristicsThese metrics translate the subjective feel of a track into quantitative data, enabling analysis of a set's energy flow and harmonic coherence.3.1.1 Audio Features: Energy, Danceability, and MoodDefinition and Utility: These psychoacoustic attributes, popularized by platforms like Spotify, provide a high-level summary of a track's sonic character.energy: A perceptual measure of intensity and activity, typically correlated with loudness and speed. A high energy value signifies a fast, loud, and noisy track (e.g., hard techno), while a low value suggests a calmer track (e.g., ambient). This metric is essential for modeling the intensity curve or "energy arc" of a DJ set.danceability: Describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity.valence: A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g., happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g., sad, depressed, angry). This is a proxy for the overall mood.Data Acquisition Method: The Spotify Web API is the definitive and most accessible source for this data. The GET /v1/audio-features/{id} endpoint returns these values directly for any track in the Spotify catalog.41 This eliminates the need for complex local audio analysis, making it a highly efficient method for any track that can be matched to a spotify_id.3.1.2 Harmonic Mixing: The Camelot KeyDefinition and Utility: Harmonic mixing is a fundamental technique in modern DJing that involves mixing tracks that are in the same or compatible musical keys. The Camelot Wheel system simplifies music theory for DJs by assigning a simple alphanumeric code (e.g., "8A" for A Minor, "8B" for C Major) to each of the 24 major and minor keys.52 Mixing between adjacent keys on the wheel (e.g., from 8A to 9A or 7A) or between the relative major/minor pair (e.g., 8A to 8B) ensures a harmonically smooth transition. Capturing the camelot_key is therefore critical for analyzing the harmonic structure and flow of a DJ set.Data Acquisition Method: The camelot_key is a derived metric that is not typically provided directly by APIs, partly due to licensing on the system itself.53 However, it can be reliably calculated programmatically in a two-step process:Obtain Standard Musical Key: First, the track's standard musical key must be obtained. The Spotify Audio Features endpoint provides this information through two fields: key (an integer from 0-11 representing pitch class, e.g., 0 = C, 1 = C#, etc.) and mode (1 for major, 0 for minor). Beatport is another excellent source for this data for electronic music.Programmatic Conversion: Once the standard key is known, a simple mapping function or dictionary can be implemented to convert it to the Camelot notation. This mapping is widely documented.54 For example, a Python function could use a dictionary lookup: camelot_map = {"A Minor": "8A", "C Major": "8B",...}. This allows for the internal calculation and storage of the camelot_key for analytical purposes.3.2 Deconstructing Track Structure for Mix Flow AnalysisDefinition and Utility: These metrics describe the arrangement of a track, which is fundamental to the physical act of mixing.intro_duration / outro_duration: The length of the beat-only or low-energy sections at the beginning and end of a track. DJs use these sections to seamlessly blend two tracks together. Analyzing these durations helps understand the type of transitions being used (e.g., long, smooth blends vs. short, quick cuts).Presence of Long Breakdowns: Identifying significant drops in rhythmic energy in the middle of a track. These are key structural moments in many forms of electronic music.Vocal Presence: Classifying a track as primarily instrumental or vocal-heavy. This influences where and how a DJ might play the track to avoid clashing vocals.Data Acquisition Method: This structural information is not available from any standard metadata API and must be derived through direct audio signal processing. This represents a significant increase in technical complexity for the data pipeline but unlocks a much deeper level of analysis.Recommended Libraries: Two industry-standard Python libraries are exceptionally well-suited for this task:librosa: A powerful and widely used library for audio analysis. It provides robust implementations of algorithms for beat tracking (librosa.beat.beat_track), onset detection, and harmonic-percussive source separation, which are the building blocks for structural analysis.55essentia: An open-source library written in C++ with Python bindings, optimized for speed, efficiency, and robustness. It offers an extensive collection of algorithms for Music Information Retrieval (MIR), including high-level descriptors for segmentation, beat tracking, and key detection.58Proposed Methodology: A high-level workflow for deriving these features would be:Obtain an audio source. The 30-second preview clips available via the Spotify API are a sufficient and legally accessible starting point.Use librosa or essentia to perform beat tracking, establishing the track's tempo and rhythmic grid.Calculate the root-mean-square (RMS) energy over short frames of the audio. Low-energy segments will correspond to intros, outros, and breakdowns.Estimate intro_duration as the time from the start of the track to the first major transient or the point where energy consistently exceeds a threshold (e.g., the first kick drum). outro_duration can be estimated symmetrically from the end.Detect vocal presence by first performing harmonic-percussive source separation and then applying a pitch detection algorithm to the harmonic component to identify melodic patterns consistent with the human voice.3.3 Contextualizing Tracks with Popularity and Influence MetricsThese metrics help quantify a track's cultural relevance and impact, both in the mainstream and within the specific context of the DJ community.3.3.1 Play Count and Popularity ScoresDefinition and Utility: These metrics provide a quantitative measure of a track's overall popularity.Data Acquisition Method:Spotify popularity: The Spotify API's GET /v1/tracks/{id} endpoint returns a popularity score from 0 to 100. This score is algorithmically determined based on the total number of plays and how recent those plays are, providing a dynamic measure of a track's current relevance.40ListenBrainz play_count: For tracks that have been matched to a musicbrainz_id, the ListenBrainz API offers an open-source alternative. Its popularity endpoints can return the total_listen_count and total_user_count for a given recording, aggregated from its user base of listening data.63 This provides a valuable, platform-agnostic popularity signal.3.3.2 Peak Chart PositionDefinition and Utility: A track's peak position on a recognized music chart (e.g., Billboard Hot 100, Official UK Top 40, Beatport Top 100) is a strong, time-stamped indicator of its mainstream or genre-specific success.Data Acquisition Method: Accessing comprehensive, historical chart data from a single free API is challenging. The strategy involves consulting multiple sources:Billboard: While an official API has existed in the past 64, current access is typically through paid, third-party APIs that provide historical chart data.65Official Charts Company (UK): This organization compiles the official UK charts but does not appear to offer a public data API.67Music Data Aggregators: Commercial services like Soundcharts and Songstats provide the most comprehensive solution by aggregating chart data from a multitude of sources, including DJ-centric stores like Beatport and Traxsource, alongside mainstream charts.68 The Songstats API, for example, has specific metrics for dj_charts from Beatport.70 While these are paid services, they offer the highest quality data for this metric.3.3.3 DJ Popularity Score (Derived Metric)Definition and Utility: This is a proposed novel metric to be calculated internally from the project's own aggregated setlist database. It is defined as the frequency with which a track appears across all collected setlists, potentially weighted by the popularity or influence of the DJs playing it. This metric is uniquely valuable because it measures a track's relevance and influence within the professional DJ community, which can be starkly different from its commercial success or streaming popularity. A track could have a low Spotify popularity score but a very high DJ Popularity Score, marking it as a "DJ's DJ" track.Data Acquisition Method: This metric is not acquired from an external source but is a product of the project's own analysis. It would be calculated by running a periodic query against the completed setlist database. A simple implementation would be a frequency count: dj_popularity_score=COUNT(track_id). A more advanced version could incorporate the follower count or RA ranking of the DJs who played the track.Table 3.1: Advanced Metadata Acquisition MethodsAdvanced FieldAnalytical UtilityAcquisition MethodComplexityenergyModels the intensity arc of a DJ set.Spotify API: GET /audio-features/{id}LowdanceabilityQuantifies rhythmic suitability for mixing.Spotify API: GET /audio-features/{id}LowvalenceMeasures the musical mood (positive/negative).Spotify API: GET /audio-features/{id}Lowcamelot_keyEnables analysis of harmonic mixing techniques.Derived: (1) Get key from Spotify/Beatport API, (2) Programmatic conversion.Lowintro_durationAnalyzes track structure for transition analysis.Audio Analysis: Python librosa/essentia on audio preview.Highoutro_durationAnalyzes track structure for transition analysis.Audio Analysis: Python librosa/essentia on audio preview.Highvocal_presenceClassifies track type for mix compatibility analysis.Audio Analysis: Source separation and pitch analysis.Highplay_countMeasures platform-agnostic listening popularity.ListenBrainz API: GET /popularity/...Mediumpeak_chart_positionIndicates mainstream or genre-specific success.Commercial APIs (e.g., Songstats, Billboard wrappers).Mediumdj_popularity_scoreMeasures influence within the DJ community.Internal Database Calculation (e.g., frequency count).MediumConclusion and Strategic RecommendationsThis report has outlined a comprehensive, multi-faceted strategy for building a large-scale database for DJ setlist analysis. The success of this endeavor hinges on a sophisticated and adaptable approach to data acquisition and enrichment, acknowledging that no single source or method is sufficient.The acquisition of raw setlist data must be a hybrid effort. High-volume platforms like YouTube and SoundCloud are essential for scale but require a significant investment in building and maintaining intelligent NLP parsers to extract structured information from unstructured text. This effort should be complemented by the targeted scraping of high-quality, genre-specific communities and forums, which provide more accurate data at a smaller scale. For genres like Hip-Hop where linear setlists are less common, the strategy must adapt to a "setlist reconstruction" model based on curated playlists and community consensus.The metadata enrichment process should be architected as a "waterfall" pipeline. This sequential model, which prioritizes high-precision identifiers (Spotify ID, ISRC) before falling back to fuzzy text searches, is the most efficient and accurate method. It strategically leverages the distinct strengths of key APIs: Spotify for its audio features and mainstream data, MusicBrainz for its canonical identifiers and relational data, and Discogs for its deep catalog of release-specific information.Finally, to unlock truly insightful analysis into the craft of DJing, the project must look beyond standard metadata. Acquiring advanced sonic features from Spotify, deriving harmonic mixing keys, and calculating structural elements through direct audio processing will enable a far more nuanced understanding of how and why DJs make their selections. The creation of an internal, derived dj_popularity_score will provide a unique metric for measuring influence within the DJ community itself.Strategic Recommendations for Implementation:Phase 1: Core Pipeline and Primary Enrichment. Begin by building the data acquisition modules for the highest value and most accessible sources, such as 1001tracklists (if available) and the YouTube Data API. Simultaneously, implement the core enrichment waterfall using the Spotify and MusicBrainz APIs, as these two sources will provide the bulk of the required metadata for matched tracks.Phase 2: Expansion and Complex Scraping. Once the core pipeline is stable, expand data acquisition to include more complex scraping targets. Prioritize sources that can be scraped efficiently (e.g., Resident Advisor via its embedded JSON) before tackling platforms that require more complex parsing (e.g., SoundCloud, Mixcloud, and various forums).Phase 3: Advanced Feature Integration. With a robust database of enriched setlists, begin implementing the acquisition of advanced metrics. Start with the low-complexity features available directly from the Spotify API (energy, danceability, etc.). The final, most resource-intensive step should be the development of the audio signal processing module to derive structural features like intro_duration, as this requires a separate infrastructure for handling and analyzing audio files. The internal dj_popularity_score can be calculated and refined as the dataset grows.By following this phased, strategic approach, the project can systematically build a powerful and unique data asset capable of yielding deep insights into the art and science of DJ curation.